{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_With_Hidden_Layers.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOs+lIAj3GaVPBXjxTcC52F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranshudiwan/NLP_CS_6200/blob/main/Bi-LSTMs_with_77_recall.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-m-F3XD5dK3"
      },
      "source": [
        "# Bi-LSTMs with Improved accuracy\n",
        "\n",
        "### Upto data cleaning part everything remains the same"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg1C7k5wT2Nk",
        "outputId": "7990b321-67a9-46b5-c8fe-428851eac3f5"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.util import ngrams\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from collections import defaultdict\n",
        "from collections import  Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.initializers import Constant\n",
        "from keras.layers import (LSTM, \n",
        "                          Embedding, \n",
        "                          BatchNormalization,\n",
        "                          Dense, \n",
        "                          TimeDistributed, \n",
        "                          Dropout, \n",
        "                          Bidirectional,\n",
        "                          Flatten, \n",
        "                          GlobalMaxPool1D)\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers.embeddings import Embedding\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.metrics import (\n",
        "    precision_score, \n",
        "    recall_score, \n",
        "    f1_score, \n",
        "    classification_report,\n",
        "    accuracy_score\n",
        ")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N82lFSp1Wrfr"
      },
      "source": [
        "# Import train data\n",
        "url_train = 'https://raw.githubusercontent.com/pranshudiwan/NLP_CS_6200/main/train.csv'\n",
        "train = pd.read_csv(url_train)\n",
        "\n",
        "# Import est data\n",
        "url_test = 'https://raw.githubusercontent.com/pranshudiwan/NLP_CS_6200/main/test.csv'\n",
        "test = pd.read_csv(url_test)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe_pdrxx4Xth"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OY5xMvLNjJ6E"
      },
      "source": [
        "#### Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1vazPBA8eur",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "56af1e3a-b5da-4631-ac3d-da189024cd4f"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo5VkZdxjMsy"
      },
      "source": [
        "#### Test Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxj1MIls8lad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "58af93d0-1f79-43c9-c8e7-c72e08179c8b"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akIoLqEX4Xrb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6whjS0vtjOrg"
      },
      "source": [
        "#### Basic Information on Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPqGcGcM8p8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17d70317-075c-42dc-c2b9-6d4782b2bbf4"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7613 non-null   int64 \n",
            " 1   keyword   7552 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      7613 non-null   object\n",
            " 4   target    7613 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 297.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRbdeqan9Sjf"
      },
      "source": [
        "Thus we have some null values in keyword and location columns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YteLePEW4XpH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "er657cX-jd4k"
      },
      "source": [
        "## Data Cleaning\n",
        "\n",
        "### 1. Removing Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkpRy3Rg9ZkX"
      },
      "source": [
        "train['text'] = train['text'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
        "#train['keyword'] = train['keyword'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
        "#train['location'] = train['location'].map(lambda x: re.sub(r'\\W+', ' ', x))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_5lfbkp9gu5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "95ed9194-cc1e-45f1-a1ac-89200f0b80d6"
      },
      "source": [
        "train.sample(5)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3010</th>\n",
              "      <td>4324</td>\n",
              "      <td>dust%20storm</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Let it be gone away like a dust in the wind Bi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6435</th>\n",
              "      <td>9208</td>\n",
              "      <td>suicide%20bombing</td>\n",
              "      <td>NaN</td>\n",
              "      <td>JewhadiTM It is almost amazing to think someo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2871</th>\n",
              "      <td>4127</td>\n",
              "      <td>drought</td>\n",
              "      <td>Meereen</td>\n",
              "      <td>Pizza drought is over I just couldn t anymore</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1559</th>\n",
              "      <td>2251</td>\n",
              "      <td>chemical%20emergency</td>\n",
              "      <td>Orbost, Victoria, Australia</td>\n",
              "      <td>Lindenow 3 15pm Emergency crews are at a chemi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4237</th>\n",
              "      <td>6020</td>\n",
              "      <td>hazardous</td>\n",
              "      <td>NaN</td>\n",
              "      <td>It s getting to be hazardous getting into this...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "3010  4324  ...      1\n",
              "6435  9208  ...      1\n",
              "2871  4127  ...      0\n",
              "1559  2251  ...      1\n",
              "4237  6020  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSCyhTXRjq0x"
      },
      "source": [
        "### 2. Converting to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtOr8KV29gxC",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "train = train.apply(lambda x: x.astype(str).str.lower())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOu8oprz9gzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "cellView": "form",
        "outputId": "058a65a7-dddb-401d-dbea-3e37c52c92b3"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "train.sample(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5023</th>\n",
              "      <td>7164</td>\n",
              "      <td>mudslide</td>\n",
              "      <td>iupui '19</td>\n",
              "      <td>someone split a mudslide w me when i get off work</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3819</th>\n",
              "      <td>5428</td>\n",
              "      <td>first%20responders</td>\n",
              "      <td>new york city</td>\n",
              "      <td>i just added sandy first responders lost their...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3038</th>\n",
              "      <td>4359</td>\n",
              "      <td>earthquake</td>\n",
              "      <td>earth</td>\n",
              "      <td>1 9 earthquake occurred 15km e of anchorage al...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7485</th>\n",
              "      <td>10707</td>\n",
              "      <td>wreck</td>\n",
              "      <td>alabama, usa</td>\n",
              "      <td>first wreck today so so glad me and mom are ok...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5300</th>\n",
              "      <td>7570</td>\n",
              "      <td>outbreak</td>\n",
              "      <td>nan</td>\n",
              "      <td>families to sue over legionnaires more than 40...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... target\n",
              "5023   7164  ...      0\n",
              "3819   5428  ...      1\n",
              "3038   4359  ...      1\n",
              "7485  10707  ...      0\n",
              "5300   7570  ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvGsfpbH9g1x"
      },
      "source": [
        ""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBGqzGFIj4VT"
      },
      "source": [
        "### 3. Removing Emojis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "QoAaFxpTjdW_",
        "cellView": "form",
        "outputId": "97ed4e49-842e-4ae5-f638-4a959b75e25f"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "train['text']=train['text'].apply(lambda x: remove_emoji(x))\n",
        "train.sample(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5809</th>\n",
              "      <td>8291</td>\n",
              "      <td>rioting</td>\n",
              "      <td>cassadaga florida</td>\n",
              "      <td>fa07af174a71408 i have lived amp my family ha...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3283</th>\n",
              "      <td>4709</td>\n",
              "      <td>epicentre</td>\n",
              "      <td>nan</td>\n",
              "      <td>epicentre cydia tweak https t co wkmfdig3nt th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1909</th>\n",
              "      <td>2744</td>\n",
              "      <td>crushed</td>\n",
              "      <td>trinidad &amp; tobago</td>\n",
              "      <td>disillusioned lead character check happy go lu...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6124</th>\n",
              "      <td>8740</td>\n",
              "      <td>sinking</td>\n",
              "      <td>hey georgia</td>\n",
              "      <td>each time we try we always end up sinking</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4403</th>\n",
              "      <td>6259</td>\n",
              "      <td>hijacking</td>\n",
              "      <td>nan</td>\n",
              "      <td>hot funtenna hijacking computers to send data...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id    keyword  ...                                               text target\n",
              "5809  8291    rioting  ...   fa07af174a71408 i have lived amp my family ha...      1\n",
              "3283  4709  epicentre  ...  epicentre cydia tweak https t co wkmfdig3nt th...      0\n",
              "1909  2744    crushed  ...  disillusioned lead character check happy go lu...      0\n",
              "6124  8740    sinking  ...          each time we try we always end up sinking      0\n",
              "4403  6259  hijacking  ...   hot funtenna hijacking computers to send data...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWx7JPlXj8cG"
      },
      "source": [
        "### 4. Correcting Spellings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcr9i7wojdZT",
        "cellView": "form",
        "outputId": "532ef7ae-d163-404d-a772-e1d15c2af5ff"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "!pip install pyspellchecker"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c7/435f49c0ac6bec031d1aba4daf94dc21dc08a9db329692cdb77faac51cea/pyspellchecker-0.6.2-py3-none-any.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 5.5MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTusYHGwj5wI",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "def correct_spellings(text):\n",
        "    corrected_text = []\n",
        "    misspelled_words = spell.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(spell.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "    return \" \".join(corrected_text)\n",
        "\n",
        "#train['text']=train['text'].apply(lambda x : correct_spellings(x))\n",
        "#train.sample(5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vhJQ6QnHj_aX"
      },
      "source": [
        "#### An example sentence passed to our spell checker function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JYQw0D2aj5yO",
        "outputId": "58cd232f-56b1-449f-ce54-42a986bffe4b"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "\n",
        "text = 'corrrect me pleas. MY NLP preject is due tomrow'\n",
        "correct_spellings(text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'correct me please MY NLP project is due tomorow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgBqr_SwkE7Y"
      },
      "source": [
        "### 5. Replacing common acronyms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JlP30DnqlFr2"
      },
      "source": [
        "Some common acronyms:\n",
        "1. idk - i don't know\n",
        "2. ttyl - talk to you later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2hEPNOLj50i",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "## Replacing common acronyms\n",
        "\n",
        "def other_clean(text):\n",
        "        \"\"\"\n",
        "            Other manual text cleaning techniques\n",
        "        \"\"\"\n",
        "        # Typos, slang and other\n",
        "        sample_typos_slang = {\n",
        "                                \"w/e\": \"whatever\",\n",
        "                                \"usagov\": \"usa government\",\n",
        "                                \"recentlu\": \"recently\",\n",
        "                                \"ph0tos\": \"photos\",\n",
        "                                \"amirite\": \"am i right\",\n",
        "                                \"exp0sed\": \"exposed\",\n",
        "                                \"<3\": \"love\",\n",
        "                                \"luv\": \"love\",\n",
        "                                \"amageddon\": \"armageddon\",\n",
        "                                \"trfc\": \"traffic\",\n",
        "                                \"16yr\": \"16 year\"\n",
        "                                }\n",
        "\n",
        "        # Acronyms\n",
        "        sample_acronyms =  { \n",
        "                            \"mh370\": \"malaysia airlines flight 370\",\n",
        "                            \"okwx\": \"oklahoma city weather\",\n",
        "                            \"arwx\": \"arkansas weather\",    \n",
        "                            \"gawx\": \"georgia weather\",  \n",
        "                            \"scwx\": \"south carolina weather\",  \n",
        "                            \"cawx\": \"california weather\",\n",
        "                            \"tnwx\": \"tennessee weather\",\n",
        "                            \"azwx\": \"arizona weather\",  \n",
        "                            \"alwx\": \"alabama weather\",\n",
        "                            \"usnwsgov\": \"united states national weather service\",\n",
        "                            \"2mw\": \"tomorrow\"\n",
        "                            }\n",
        "\n",
        "        \n",
        "        # Some common abbreviations \n",
        "        sample_abbr = {\n",
        "                        \"$\" : \" dollar \",\n",
        "                        \"€\" : \" euro \",\n",
        "                        \"4ao\" : \"for adults only\",\n",
        "                        \"a.m\" : \"before midday\",\n",
        "                        \"a3\" : \"anytime anywhere anyplace\",\n",
        "                        \"aamof\" : \"as a matter of fact\",\n",
        "                        \"acct\" : \"account\",\n",
        "                        \"adih\" : \"another day in hell\",\n",
        "                        \"afaic\" : \"as far as i am concerned\",\n",
        "                        \"afaict\" : \"as far as i can tell\",\n",
        "                        \"afaik\" : \"as far as i know\",\n",
        "                        \"afair\" : \"as far as i remember\",\n",
        "                        \"afk\" : \"away from keyboard\",\n",
        "                        \"app\" : \"application\",\n",
        "                        \"approx\" : \"approximately\",\n",
        "                        \"apps\" : \"applications\",\n",
        "                        \"asap\" : \"as soon as possible\",\n",
        "                        \"asl\" : \"age, sex, location\",\n",
        "                        \"atk\" : \"at the keyboard\",\n",
        "                        \"ave.\" : \"avenue\",\n",
        "                        \"aymm\" : \"are you my mother\",\n",
        "                        \"ayor\" : \"at your own risk\", \n",
        "                        \"b&b\" : \"bed and breakfast\",\n",
        "                        \"b+b\" : \"bed and breakfast\",\n",
        "                        \"b.c\" : \"before christ\",\n",
        "                        \"b2b\" : \"business to business\",\n",
        "                        \"b2c\" : \"business to customer\",\n",
        "                        \"b4\" : \"before\",\n",
        "                        \"b4n\" : \"bye for now\",\n",
        "                        \"b@u\" : \"back at you\",\n",
        "                        \"bae\" : \"before anyone else\",\n",
        "                        \"bak\" : \"back at keyboard\",\n",
        "                        \"bbbg\" : \"bye bye be good\",\n",
        "                        \"bbc\" : \"british broadcasting corporation\",\n",
        "                        \"bbias\" : \"be back in a second\",\n",
        "                        \"bbl\" : \"be back later\",\n",
        "                        \"bbs\" : \"be back soon\",\n",
        "                        \"be4\" : \"before\",\n",
        "                        \"bfn\" : \"bye for now\",\n",
        "                        \"blvd\" : \"boulevard\",\n",
        "                        \"bout\" : \"about\",\n",
        "                        \"brb\" : \"be right back\",\n",
        "                        \"bros\" : \"brothers\",\n",
        "                        \"brt\" : \"be right there\",\n",
        "                        \"bsaaw\" : \"big smile and a wink\",\n",
        "                        \"btw\" : \"by the way\",\n",
        "                        \"bwl\" : \"bursting with laughter\",\n",
        "                        \"c/o\" : \"care of\",\n",
        "                        \"cet\" : \"central european time\",\n",
        "                        \"cf\" : \"compare\",\n",
        "                        \"cia\" : \"central intelligence agency\",\n",
        "                        \"csl\" : \"can not stop laughing\",\n",
        "                        \"cu\" : \"see you\",\n",
        "                        \"cul8r\" : \"see you later\",\n",
        "                        \"cv\" : \"curriculum vitae\",\n",
        "                        \"cwot\" : \"complete waste of time\",\n",
        "                        \"cya\" : \"see you\",\n",
        "                        \"cyt\" : \"see you tomorrow\",\n",
        "                        \"dae\" : \"does anyone else\",\n",
        "                        \"dbmib\" : \"do not bother me i am busy\",\n",
        "                        \"diy\" : \"do it yourself\",\n",
        "                        \"dm\" : \"direct message\",\n",
        "                        \"dwh\" : \"during work hours\",\n",
        "                        \"e123\" : \"easy as one two three\",\n",
        "                        \"eet\" : \"eastern european time\",\n",
        "                        \"eg\" : \"example\",\n",
        "                        \"embm\" : \"early morning business meeting\",\n",
        "                        \"encl\" : \"enclosed\",\n",
        "                        \"encl.\" : \"enclosed\",\n",
        "                        \"etc\" : \"and so on\",\n",
        "                        \"faq\" : \"frequently asked questions\",\n",
        "                        \"fawc\" : \"for anyone who cares\",\n",
        "                        \"fb\" : \"facebook\",\n",
        "                        \"fc\" : \"fingers crossed\",\n",
        "                        \"fig\" : \"figure\",\n",
        "                        \"fimh\" : \"forever in my heart\", \n",
        "                        \"ft.\" : \"feet\",\n",
        "                        \"ft\" : \"featuring\",\n",
        "                        \"ftl\" : \"for the loss\",\n",
        "                        \"ftw\" : \"for the win\",\n",
        "                        \"fwiw\" : \"for what it is worth\",\n",
        "                        \"fyi\" : \"for your information\",\n",
        "                        \"g9\" : \"genius\",\n",
        "                        \"gahoy\" : \"get a hold of yourself\",\n",
        "                        \"gal\" : \"get a life\",\n",
        "                        \"gcse\" : \"general certificate of secondary education\",\n",
        "                        \"gfn\" : \"gone for now\",\n",
        "                        \"gg\" : \"good game\",\n",
        "                        \"gl\" : \"good luck\",\n",
        "                        \"glhf\" : \"good luck have fun\",\n",
        "                        \"gmt\" : \"greenwich mean time\",\n",
        "                        \"gmta\" : \"great minds think alike\",\n",
        "                        \"gn\" : \"good night\",\n",
        "                        \"g.o.a.t\" : \"greatest of all time\",\n",
        "                        \"goat\" : \"greatest of all time\",\n",
        "                        \"goi\" : \"get over it\",\n",
        "                        \"gps\" : \"global positioning system\",\n",
        "                        \"gr8\" : \"great\",\n",
        "                        \"gratz\" : \"congratulations\",\n",
        "                        \"gyal\" : \"girl\",\n",
        "                        \"h&c\" : \"hot and cold\",\n",
        "                        \"hp\" : \"horsepower\",\n",
        "                        \"hr\" : \"hour\",\n",
        "                        \"hrh\" : \"his royal highness\",\n",
        "                        \"ht\" : \"height\",\n",
        "                        \"ibrb\" : \"i will be right back\",\n",
        "                        \"ic\" : \"i see\",\n",
        "                        \"icq\" : \"i seek you\",\n",
        "                        \"icymi\" : \"in case you missed it\",\n",
        "                        \"idc\" : \"i do not care\",\n",
        "                        \"idgadf\" : \"i do not give a damn fuck\",\n",
        "                        \"idgaf\" : \"i do not give a fuck\",\n",
        "                        \"idk\" : \"i do not know\",\n",
        "                        \"ie\" : \"that is\",\n",
        "                        \"i.e\" : \"that is\",\n",
        "                        \"ifyp\" : \"i feel your pain\",\n",
        "                        \"IG\" : \"instagram\",\n",
        "                        \"iirc\" : \"if i remember correctly\",\n",
        "                        \"ilu\" : \"i love you\",\n",
        "                        \"ily\" : \"i love you\",\n",
        "                        \"imho\" : \"in my humble opinion\",\n",
        "                        \"imo\" : \"in my opinion\",\n",
        "                        \"imu\" : \"i miss you\",\n",
        "                        \"iow\" : \"in other words\",\n",
        "                        \"irl\" : \"in real life\",\n",
        "                        \"j4f\" : \"just for fun\",\n",
        "                        \"jic\" : \"just in case\",\n",
        "                        \"jk\" : \"just kidding\",\n",
        "                        \"jsyk\" : \"just so you know\",\n",
        "                        \"l8r\" : \"later\",\n",
        "                        \"lb\" : \"pound\",\n",
        "                        \"lbs\" : \"pounds\",\n",
        "                        \"ldr\" : \"long distance relationship\",\n",
        "                        \"lmao\" : \"laugh my ass off\",\n",
        "                        \"lmfao\" : \"laugh my fucking ass off\",\n",
        "                        \"lol\" : \"laughing out loud\",\n",
        "                        \"ltd\" : \"limited\",\n",
        "                        \"ltns\" : \"long time no see\",\n",
        "                        \"m8\" : \"mate\",\n",
        "                        \"mf\" : \"motherfucker\",\n",
        "                        \"mfs\" : \"motherfuckers\",\n",
        "                        \"mfw\" : \"my face when\",\n",
        "                        \"mofo\" : \"motherfucker\",\n",
        "                        \"mph\" : \"miles per hour\",\n",
        "                        \"mr\" : \"mister\",\n",
        "                        \"mrw\" : \"my reaction when\",\n",
        "                        \"ms\" : \"miss\",\n",
        "                        \"mte\" : \"my thoughts exactly\",\n",
        "                        \"nagi\" : \"not a good idea\",\n",
        "                        \"nbc\" : \"national broadcasting company\",\n",
        "                        \"nbd\" : \"not big deal\",\n",
        "                        \"nfs\" : \"not for sale\",\n",
        "                        \"ngl\" : \"not going to lie\",\n",
        "                        \"nhs\" : \"national health service\",\n",
        "                        \"nrn\" : \"no reply necessary\",\n",
        "                        \"nsfl\" : \"not safe for life\",\n",
        "                        \"nsfw\" : \"not safe for work\",\n",
        "                        \"nth\" : \"nice to have\",\n",
        "                        \"nvr\" : \"never\",\n",
        "                        \"nyc\" : \"new york city\",\n",
        "                        \"oc\" : \"original content\",\n",
        "                        \"og\" : \"original\",\n",
        "                        \"ohp\" : \"overhead projector\",\n",
        "                        \"oic\" : \"oh i see\",\n",
        "                        \"omdb\" : \"over my dead body\",\n",
        "                        \"omg\" : \"oh my god\",\n",
        "                        \"omw\" : \"on my way\",\n",
        "                        \"p.a\" : \"per annum\",\n",
        "                        \"p.m\" : \"after midday\",\n",
        "                        \"pm\" : \"prime minister\",\n",
        "                        \"poc\" : \"people of color\",\n",
        "                        \"pov\" : \"point of view\",\n",
        "                        \"pp\" : \"pages\",\n",
        "                        \"ppl\" : \"people\",\n",
        "                        \"prw\" : \"parents are watching\",\n",
        "                        \"ps\" : \"postscript\",\n",
        "                        \"pt\" : \"point\",\n",
        "                        \"ptb\" : \"please text back\",\n",
        "                        \"pto\" : \"please turn over\",\n",
        "                        \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "                        \"ratchet\" : \"rude\",\n",
        "                        \"rbtl\" : \"read between the lines\",\n",
        "                        \"rlrt\" : \"real life retweet\", \n",
        "                        \"rofl\" : \"rolling on the floor laughing\",\n",
        "                        \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "                        \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "                        \"rt\" : \"retweet\",\n",
        "                        \"ruok\" : \"are you ok\",\n",
        "                        \"sfw\" : \"safe for work\",\n",
        "                        \"sk8\" : \"skate\",\n",
        "                        \"smh\" : \"shake my head\",\n",
        "                        \"sq\" : \"square\",\n",
        "                        \"srsly\" : \"seriously\", \n",
        "                        \"ssdd\" : \"same stuff different day\",\n",
        "                        \"tbh\" : \"to be honest\",\n",
        "                        \"tbs\" : \"tablespooful\",\n",
        "                        \"tbsp\" : \"tablespooful\",\n",
        "                        \"tfw\" : \"that feeling when\",\n",
        "                        \"thks\" : \"thank you\",\n",
        "                        \"tho\" : \"though\",\n",
        "                        \"thx\" : \"thank you\",\n",
        "                        \"tia\" : \"thanks in advance\",\n",
        "                        \"til\" : \"today i learned\",\n",
        "                        \"tl;dr\" : \"too long i did not read\",\n",
        "                        \"tldr\" : \"too long i did not read\",\n",
        "                        \"tmb\" : \"tweet me back\",\n",
        "                        \"tntl\" : \"trying not to laugh\",\n",
        "                        \"ttyl\" : \"talk to you later\",\n",
        "                        \"u\" : \"you\",\n",
        "                        \"u2\" : \"you too\",\n",
        "                        \"u4e\" : \"yours for ever\",\n",
        "                        \"utc\" : \"coordinated universal time\",\n",
        "                        \"w/\" : \"with\",\n",
        "                        \"w/o\" : \"without\",\n",
        "                        \"w8\" : \"wait\",\n",
        "                        \"wassup\" : \"what is up\",\n",
        "                        \"wb\" : \"welcome back\",\n",
        "                        \"wtf\" : \"what the fuck\",\n",
        "                        \"wtg\" : \"way to go\",\n",
        "                        \"wtpa\" : \"where the party at\",\n",
        "                        \"wuf\" : \"where are you from\",\n",
        "                        \"wuzup\" : \"what is up\",\n",
        "                        \"wywh\" : \"wish you were here\",\n",
        "                        \"yd\" : \"yard\",\n",
        "                        \"ygtr\" : \"you got that right\",\n",
        "                        \"ynk\" : \"you never know\",\n",
        "                        \"zzz\" : \"sleeping bored and tired\"\n",
        "                        }\n",
        "            \n",
        "        sample_typos_slang_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_typos_slang.keys()) + r')(?!\\w)')\n",
        "        sample_acronyms_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_acronyms.keys()) + r')(?!\\w)')\n",
        "        sample_abbr_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_abbr.keys()) + r')(?!\\w)')\n",
        "        \n",
        "        text = sample_typos_slang_pattern.sub(lambda x: sample_typos_slang[x.group()], text)\n",
        "        text = sample_acronyms_pattern.sub(lambda x: sample_acronyms[x.group()], text)\n",
        "        text = sample_abbr_pattern.sub(lambda x: sample_abbr[x.group()], text)\n",
        "        \n",
        "        return text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "id": "EXhuQe_XkK2z",
        "cellView": "form",
        "outputId": "9d8aa79f-b214-498a-d05c-e056945895b2"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "## !Need to change variable names and abbrevations as appropriate\n",
        "train[\"text\"] = train[\"text\"].apply(lambda x: other_clean(x))\n",
        "train.sample(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>782</td>\n",
              "      <td>avalanche</td>\n",
              "      <td>buy give me my money</td>\n",
              "      <td>great one time deal on all avalanche music and...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7259</th>\n",
              "      <td>10393</td>\n",
              "      <td>whirlwind</td>\n",
              "      <td>nan</td>\n",
              "      <td>sitting in a cafe enjoying a bite and cramming...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3645</th>\n",
              "      <td>5194</td>\n",
              "      <td>fatalities</td>\n",
              "      <td>san francisco</td>\n",
              "      <td>motordom lobbied to change our language aroun...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>4260</td>\n",
              "      <td>drowning</td>\n",
              "      <td>nan</td>\n",
              "      <td>drowning acrylic 08 05 15 https t co x17fubqbgg</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1887</th>\n",
              "      <td>2711</td>\n",
              "      <td>crushed</td>\n",
              "      <td>nan</td>\n",
              "      <td>http t co kg5plkedhr wrapup 2 you s cable tv c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... target\n",
              "537     782  ...      0\n",
              "7259  10393  ...      0\n",
              "3645   5194  ...      0\n",
              "2965   4260  ...      1\n",
              "1887   2711  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb8JVZubkK40",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDvaDUafkS6y"
      },
      "source": [
        "### 6. Removing single and unwanted characters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJFG-NYzkK6S",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "## Removing single characters\n",
        "train[\"text\"] = train[\"text\"].str.replace(r'\\b\\w\\b','').str.replace(r'\\s+', ' ')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdcs8qPIn1D_",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TeNAqBKkbFZ"
      },
      "source": [
        "### 7. Removing common stop-words and tokenizing the text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA7F95bp9g3-",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "def tokenizer(text):\n",
        "    tokenized = []\n",
        "    for string in text:\n",
        "        string = re.sub('[^a-z\\sA-Z]', '', string)\n",
        "        string = re.sub('http\\S+', '', string)\n",
        "        string = re.sub('co', '', string)\n",
        "        string = re.sub('via', '', string)\n",
        "        string = re.sub('amp', '', string)\n",
        "        tokenized.append([w for w in string.split() if w not in stop])\n",
        "    return tokenized"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InA0iUEGnkPN",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "train['tokenized'] = tokenizer(train[\"text\"])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYBuqfVnn4Qr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "cellView": "form",
        "outputId": "3e84dbfe-bec4-41f9-bd17-72e570f10a18"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "train.sample(5)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6491</th>\n",
              "      <td>9280</td>\n",
              "      <td>sunk</td>\n",
              "      <td>nan</td>\n",
              "      <td>shekhargupta mihirssharma high time tv channe...</td>\n",
              "      <td>0</td>\n",
              "      <td>[shekhargupta, mihirssharma, high, time, tv, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>144</td>\n",
              "      <td>accident</td>\n",
              "      <td>uk</td>\n",
              "      <td>norwaymfa bahrain police had previously died ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[norwaymfa, bahrain, police, previously, died,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>435</td>\n",
              "      <td>apocalypse</td>\n",
              "      <td>nan</td>\n",
              "      <td>minecraft night lucky block mod bob apocalypse...</td>\n",
              "      <td>0</td>\n",
              "      <td>[minecraft, night, lucky, block, mod, bob, apo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1786</th>\n",
              "      <td>2564</td>\n",
              "      <td>crash</td>\n",
              "      <td>liverpool</td>\n",
              "      <td>party for bestival crash victim michael molloy...</td>\n",
              "      <td>1</td>\n",
              "      <td>[party, bestival, crash, victim, michael, moll...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3062</th>\n",
              "      <td>4393</td>\n",
              "      <td>earthquake</td>\n",
              "      <td>london</td>\n",
              "      <td>there was small earthquake in la but don worr...</td>\n",
              "      <td>1</td>\n",
              "      <td>[small, earthquake, la, worry, emmy, rossum, f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                          tokenized\n",
              "6491  9280  ...  [shekhargupta, mihirssharma, high, time, tv, c...\n",
              "100    144  ...  [norwaymfa, bahrain, police, previously, died,...\n",
              "295    435  ...  [minecraft, night, lucky, block, mod, bob, apo...\n",
              "1786  2564  ...  [party, bestival, crash, victim, michael, moll...\n",
              "3062  4393  ...  [small, earthquake, la, worry, emmy, rossum, f...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeHxJK7nkicZ"
      },
      "source": [
        "### 8. Performing stemming"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbkkU1Fjo8o9",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "# Performing stemming\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA3wSqdSp-p5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "a69c0238-d2b6-4eb0-b4c9-02759fd48ab9"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbjHrFSWrEiz",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7eOzoOwpZTp",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "def stem(unstemmed_list):  \n",
        "  ps = PorterStemmer()\n",
        "\n",
        "  final_stemmed_list = []\n",
        "\n",
        "  for i in range(len(unstemmed_list)):\n",
        "    sentence = unstemmed_list[i]\n",
        "    #print(sentence)\n",
        "    words = word_tokenize(sentence)\n",
        "    stemmed_list = []\n",
        "    for w in words:\n",
        "        stemmed_list.append(ps.stem(w))\n",
        "    stemmed_list = ' '.join(stemmed_list)\n",
        "    final_stemmed_list.append(stemmed_list)\n",
        "\n",
        "  return final_stemmed_list\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX6jvSfdrkbX",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "unstemmed_list = train['text'].tolist()\n",
        "train['stemmed_text'] = stem(unstemmed_list)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8KYRf1trkdo",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "#Removing digits\n",
        "train['stemmed_text'] = train['stemmed_text'].str.replace('\\d+', '')"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iatokNiHsBcZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "cellView": "form",
        "outputId": "46ec758e-4008-4074-c54b-32def680fd7d"
      },
      "source": [
        "#@title\n",
        "#@title\n",
        "train.sample(5)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stemmed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5713</th>\n",
              "      <td>8154</td>\n",
              "      <td>rescuers</td>\n",
              "      <td>nan</td>\n",
              "      <td>have an unexplainable desire to watch the res...</td>\n",
              "      <td>0</td>\n",
              "      <td>[unexplainable, desire, watch, rescuers, child...</td>\n",
              "      <td>have an unexplain desir to watch the rescuer c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2494</th>\n",
              "      <td>3583</td>\n",
              "      <td>desolate</td>\n",
              "      <td>michigan, usa</td>\n",
              "      <td>psalm34 22 the lord redeemeth the soul of his ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[psalm, lord, redeemeth, soul, servants, none,...</td>\n",
              "      <td>psalm  the lord redeemeth the soul of hi serva...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5118</th>\n",
              "      <td>7299</td>\n",
              "      <td>nuclear%20reactor</td>\n",
              "      <td>washington, d.c.</td>\n",
              "      <td>global nuclear reactor construction market gre...</td>\n",
              "      <td>1</td>\n",
              "      <td>[global, nuclear, reactor, nstruction, market,...</td>\n",
              "      <td>global nuclear reactor construct market grew b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5288</th>\n",
              "      <td>7555</td>\n",
              "      <td>outbreak</td>\n",
              "      <td>nj/nyc</td>\n",
              "      <td>wow the name legionnairesdisease comes from an...</td>\n",
              "      <td>1</td>\n",
              "      <td>[wow, name, legionnairesdisease, mes, outbreak...</td>\n",
              "      <td>wow the name legionnairesdiseas come from an o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2414</th>\n",
              "      <td>3473</td>\n",
              "      <td>derailed</td>\n",
              "      <td>dc, frequently nyc/san diego</td>\n",
              "      <td>whoa wmata train derailed at smithsonian</td>\n",
              "      <td>1</td>\n",
              "      <td>[whoa, wmata, train, derailed, smithsonian]</td>\n",
              "      <td>whoa wmata train derail at smithsonian</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                       stemmed_text\n",
              "5713  8154  ...  have an unexplain desir to watch the rescuer c...\n",
              "2494  3583  ...  psalm  the lord redeemeth the soul of hi serva...\n",
              "5118  7299  ...  global nuclear reactor construct market grew b...\n",
              "5288  7555  ...  wow the name legionnairesdiseas come from an o...\n",
              "2414  3473  ...             whoa wmata train derail at smithsonian\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jon1sPtHsBeo",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#@title\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNFhddBVkmZ2"
      },
      "source": [
        "We are thus done with our data cleaning part here. We will continue to build models on the clean data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGT6H8QpsRLG"
      },
      "source": [
        "## Bi-LSTMs for better accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR43JIxe4XRi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AH4HfD5zW6Ts"
      },
      "source": [
        "tweet_1 = train.text.values\n",
        "test_1 = train.text.values\n",
        "sentiments = tweet.target.values"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-qPL92XXIx8"
      },
      "source": [
        "word_tokenizer = Tokenizer()\n",
        "word_tokenizer.fit_on_texts(tweet_1)\n",
        "vocab_length = len(word_tokenizer.word_index) + 1"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abVf873QXKcD"
      },
      "source": [
        "def metrics(pred_tag, y_test):\n",
        "    print(\"F1-score: \", f1_score(pred_tag, y_test))\n",
        "    print(\"Precision: \", precision_score(pred_tag, y_test))\n",
        "    print(\"Recall: \", recall_score(pred_tag, y_test))\n",
        "    print(\"Acuracy: \", accuracy_score(pred_tag, y_test))\n",
        "    #print(\"-\"*50)\n",
        "    #print(classification_report(pred_tag, y_test))\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfqkrhPbXMPS"
      },
      "source": [
        "def embed(corpus): \n",
        "    return word_tokenizer.texts_to_sequences(corpus)"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnF527m2XN41",
        "outputId": "675cf0da-c175-4309-e418-951716094683"
      },
      "source": [
        "nltk.download('punkt')\n",
        "longest_train = max(tweet_1, key=lambda sentence: len(word_tokenize(sentence)))\n",
        "length_long_sentence = len(word_tokenize(longest_train))\n",
        "padded_sentences = pad_sequences(embed(tweet_1), length_long_sentence, padding='post')\n",
        "test_sentences = pad_sequences(\n",
        "    embed(test_1), \n",
        "    length_long_sentence,\n",
        "    padding='post'\n",
        ")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzJ-daq-XUoz"
      },
      "source": [
        ""
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yqs-TCixYSZA",
        "outputId": "6ae3cb76-0793-4c90-de27-45cd7f002a9e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXhC2n_VYrsz"
      },
      "source": [
        ""
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSgsuXTgXPhU"
      },
      "source": [
        "embeddings_dictionary = dict()\n",
        "embedding_dim = 200\n",
        "glove_file = open('/content/drive/My Drive/glove.6B.200d.txt')\n",
        "for line in glove_file:\n",
        "    records = line.split()\n",
        "    word = records[0]\n",
        "    vector_dimensions = np.asarray(records[1:], dtype='float32')\n",
        "    embeddings_dictionary [word] = vector_dimensions\n",
        "glove_file.close()"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLzPKAikYLFk"
      },
      "source": [
        "embedding_matrix = np.zeros((vocab_length, embedding_dim))\n",
        "for word, index in word_tokenizer.word_index.items():\n",
        "    embedding_vector = embeddings_dictionary.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[index] = embedding_vector"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA1h_k4_Y3wi"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    padded_sentences, \n",
        "    sentiments, \n",
        "    test_size=0.25\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26yoplGQZAQ9"
      },
      "source": [
        "def BLSTM():\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=embedding_matrix.shape[0], \n",
        "                        output_dim=embedding_matrix.shape[1], \n",
        "                        weights = [embedding_matrix], \n",
        "                        input_length=length_long_sentence))\n",
        "    model.add(Bidirectional(LSTM(length_long_sentence, return_sequences = True, recurrent_dropout=0.2)))\n",
        "    model.add(GlobalMaxPool1D())\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(length_long_sentence, activation = \"relu\"))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation = 'sigmoid'))\n",
        "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtq3uclXZB3Y",
        "outputId": "905afc40-e18e-44a6-97ec-792e4559f00f"
      },
      "source": [
        "model = BLSTM()\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'model.h5', \n",
        "    monitor = 'val_loss', \n",
        "    verbose = 1, \n",
        "    save_best_only = True\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor = 'val_loss', \n",
        "    factor = 0.2, \n",
        "    verbose = 1, \n",
        "    patience = 5,                        \n",
        "    min_lr = 0.001\n",
        ")\n",
        "history = model.fit(\n",
        "    X_train, \n",
        "    y_train, \n",
        "    epochs = 7,\n",
        "    batch_size = 32,\n",
        "    validation_data = [X_test, y_test],\n",
        "    verbose = 1,\n",
        "    callbacks = [reduce_lr, checkpoint]\n",
        ")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "179/179 [==============================] - 21s 85ms/step - loss: 0.8056 - accuracy: 0.5584 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.00000, saving model to model.h5\n",
            "Epoch 2/7\n",
            "179/179 [==============================] - 14s 80ms/step - loss: 0.5920 - accuracy: 0.7044 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00002: val_loss did not improve from 0.00000\n",
            "Epoch 3/7\n",
            "179/179 [==============================] - 14s 79ms/step - loss: 0.4905 - accuracy: 0.7838 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.00000\n",
            "Epoch 4/7\n",
            "179/179 [==============================] - 14s 79ms/step - loss: 0.4462 - accuracy: 0.8111 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00004: val_loss did not improve from 0.00000\n",
            "Epoch 5/7\n",
            "179/179 [==============================] - 14s 80ms/step - loss: 0.4229 - accuracy: 0.8312 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.00000\n",
            "Epoch 6/7\n",
            "179/179 [==============================] - 14s 79ms/step - loss: 0.3734 - accuracy: 0.8528 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.00000\n",
            "Epoch 7/7\n",
            "179/179 [==============================] - 14s 78ms/step - loss: 0.3535 - accuracy: 0.8590 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.00000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XNAfh4gfZ6PD",
        "outputId": "4bfa3afc-f35c-45cc-c94c-932fdede6998"
      },
      "source": [
        "lstm = BLSTM()\n",
        "lstm.summary()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 31, 200)           4317000   \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 31, 62)            57536     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 62)                0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 62)                248       \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 62)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 31)                1953      \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 31)                0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 31)                992       \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 31)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 32        \n",
            "=================================================================\n",
            "Total params: 4,377,761\n",
            "Trainable params: 4,377,637\n",
            "Non-trainable params: 124\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EbJ-Gf_ZHzt"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFtRygzcZN_g"
      },
      "source": [
        ""
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM6JyjMCZOV-",
        "outputId": "885e2e2d-63d2-4a17-da49-97f068fcae56"
      },
      "source": [
        "preds = model.predict_classes(X_test)\n",
        "metrics(preds, y_test)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1-score:  0.7824474660074165\n",
            "Precision:  0.798234552332913\n",
            "Recall:  0.7672727272727272\n",
            "Acuracy:  0.8151260504201681\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CHRIhzx6brY"
      },
      "source": [
        "### Thus, we got a recall of 76.7%, which is a significant improvement over other methods"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ez6ISEnMZPxH"
      },
      "source": [
        ""
      ],
      "execution_count": 50,
      "outputs": []
    }
  ]
}