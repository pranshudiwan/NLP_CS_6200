{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_doc2vec+wordcloud.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pranshudiwan/NLP_CS_6200/blob/main/NLP_doc2vec%2Bwordcloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_p4mvnCjhCs8"
      },
      "source": [
        "# Import Libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoYVyeq38M2n"
      },
      "source": [
        "# Import train data\n",
        "url_train = 'https://raw.githubusercontent.com/pranshudiwan/NLP_CS_6200/main/train.csv'\n",
        "train = pd.read_csv(url_train)\n",
        "\n",
        "# Import est data\n",
        "url_test = 'https://raw.githubusercontent.com/pranshudiwan/NLP_CS_6200/main/test.csv'\n",
        "test = pd.read_csv(url_test)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1vazPBA8eur",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8edaa75c-276d-4983-acc1-f4eed3a1bbdf"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxj1MIls8lad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "49774d36-3f66-4402-b77b-eb170e04e021"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPqGcGcM8p8s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5347341f-12a3-41d3-df34-e2315ff07b3e"
      },
      "source": [
        "train.info()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7613 entries, 0 to 7612\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   id        7613 non-null   int64 \n",
            " 1   keyword   7552 non-null   object\n",
            " 2   location  5080 non-null   object\n",
            " 3   text      7613 non-null   object\n",
            " 4   target    7613 non-null   int64 \n",
            "dtypes: int64(2), object(3)\n",
            "memory usage: 297.5+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRbdeqan9Sjf"
      },
      "source": [
        "Thus we have some null values in keyword and location columns. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yx1sLwW69PVT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "outputId": "257cfeb1-0f0c-4cd2-df91-97309b7ffc9e"
      },
      "source": [
        "train.sample(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3530</th>\n",
              "      <td>5046</td>\n",
              "      <td>eyewitness</td>\n",
              "      <td>UK</td>\n",
              "      <td>RT patrickjbutler: Excellent damiengayle eyewi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6613</th>\n",
              "      <td>9469</td>\n",
              "      <td>terrorism</td>\n",
              "      <td>Reston, VA, USA</td>\n",
              "      <td>A good piece on Israeli incitement and Jewish ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2590</th>\n",
              "      <td>3718</td>\n",
              "      <td>destroyed</td>\n",
              "      <td>USA</td>\n",
              "      <td>Black Eye 9: A space battle occurred at Star O...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5542</th>\n",
              "      <td>7907</td>\n",
              "      <td>radiation%20emergency</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Who Else Wants Documents Radiation Emergency P...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5181</th>\n",
              "      <td>7393</td>\n",
              "      <td>obliterate</td>\n",
              "      <td>London</td>\n",
              "      <td>'We are now prepared to obliterate more rapidl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5050</th>\n",
              "      <td>7198</td>\n",
              "      <td>natural%20disaster</td>\n",
              "      <td>Los Angeles</td>\n",
              "      <td>On the sneak America has us spoiled. A natural...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2965</th>\n",
              "      <td>4260</td>\n",
              "      <td>drowning</td>\n",
              "      <td>NaN</td>\n",
              "      <td>'Drowning' - Acrylic 08.05.15 https://t.co/X17...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6975</th>\n",
              "      <td>10005</td>\n",
              "      <td>tsunami</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All of this energy</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7335</th>\n",
              "      <td>10500</td>\n",
              "      <td>wildfire</td>\n",
              "      <td>Worldwide</td>\n",
              "      <td>California wildfire destroys more homes but cr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6628</th>\n",
              "      <td>9492</td>\n",
              "      <td>terrorist</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Captured terrorist Naved not registered as our...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... target\n",
              "3530   5046  ...      1\n",
              "6613   9469  ...      1\n",
              "2590   3718  ...      0\n",
              "5542   7907  ...      0\n",
              "5181   7393  ...      0\n",
              "5050   7198  ...      1\n",
              "2965   4260  ...      1\n",
              "6975  10005  ...      0\n",
              "7335  10500  ...      1\n",
              "6628   9492  ...      1\n",
              "\n",
              "[10 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkpRy3Rg9ZkX"
      },
      "source": [
        "import re\n",
        "train['text'] = train['text'].map(lambda x: re.sub(r'\\W+', ' ', x))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_5lfbkp9gu5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "1570a76e-e5fc-4442-d876-af190ec240c2"
      },
      "source": [
        "train.sample(5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5146</th>\n",
              "      <td>7338</td>\n",
              "      <td>nuclear%20reactor</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Finnish ministers Fennovoima nuclear reactor w...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3696</th>\n",
              "      <td>5259</td>\n",
              "      <td>fatality</td>\n",
              "      <td>Honduras</td>\n",
              "      <td>Fatality</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5712</th>\n",
              "      <td>8150</td>\n",
              "      <td>rescuers</td>\n",
              "      <td>Africa</td>\n",
              "      <td>Durban_Knight Rescuers are searching for hund...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1386</th>\n",
              "      <td>1999</td>\n",
              "      <td>bush%20fires</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ted Cruz fires back at Jeb amp Bush ÛÏWe lose ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7065</th>\n",
              "      <td>10119</td>\n",
              "      <td>upheaval</td>\n",
              "      <td>Auckland, New Zealand</td>\n",
              "      <td>An indepth look at the new world of work and h...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... target\n",
              "5146   7338  ...      0\n",
              "3696   5259  ...      0\n",
              "5712   8150  ...      1\n",
              "1386   1999  ...      0\n",
              "7065  10119  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtOr8KV29gxC"
      },
      "source": [
        "train = train.apply(lambda x: x.astype(str).str.lower())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOu8oprz9gzw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "899d0b29-7e6a-47eb-b28b-5090043cfb19"
      },
      "source": [
        "train.sample(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4656</th>\n",
              "      <td>6621</td>\n",
              "      <td>inundated</td>\n",
              "      <td>singapore</td>\n",
              "      <td>myanmar s president urged people to leave a lo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1214</th>\n",
              "      <td>1752</td>\n",
              "      <td>buildings%20burning</td>\n",
              "      <td>epic city, bb.</td>\n",
              "      <td>i pledge allegiance to the p o p e and the bur...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1845</th>\n",
              "      <td>2655</td>\n",
              "      <td>crush</td>\n",
              "      <td>kaneohe</td>\n",
              "      <td>kuualohax more like you love your husband but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7483</th>\n",
              "      <td>10705</td>\n",
              "      <td>wreck</td>\n",
              "      <td>sf bay area, california / greater phoenix, az</td>\n",
              "      <td>anyone know if fox ûïnews û will be live strea...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1001</th>\n",
              "      <td>1453</td>\n",
              "      <td>body%20bagging</td>\n",
              "      <td>nan</td>\n",
              "      <td>i m not a drake fan but i enjoy seeing him bod...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... target\n",
              "4656   6621  ...      1\n",
              "1214   1752  ...      0\n",
              "1845   2655  ...      0\n",
              "7483  10705  ...      0\n",
              "1001   1453  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvGsfpbH9g1x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 271
        },
        "outputId": "0bfc6501-a47e-42f6-8ddc-5447b789f30d"
      },
      "source": [
        "train['keyword'] = train['keyword'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
        "train['location'] = train['location'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
        "train.sample(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5672</th>\n",
              "      <td>8095</td>\n",
              "      <td>rescued</td>\n",
              "      <td>nan</td>\n",
              "      <td>britons rescued amid himalaya floods http t co...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2719</th>\n",
              "      <td>3905</td>\n",
              "      <td>devastated</td>\n",
              "      <td>republica dominicana</td>\n",
              "      <td>losdelsonido obama declares disaster for typh...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3739</th>\n",
              "      <td>5315</td>\n",
              "      <td>fire</td>\n",
              "      <td>sì o paulo</td>\n",
              "      <td>marquei como visto game of thrones 3x5 kissed ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6209</th>\n",
              "      <td>8859</td>\n",
              "      <td>smoke</td>\n",
              "      <td>soufside</td>\n",
              "      <td>niggas selling weed just so they can smoke amp...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1009</th>\n",
              "      <td>1464</td>\n",
              "      <td>body 20bagging</td>\n",
              "      <td>nan</td>\n",
              "      <td>mzgraciebaby for the record im jumpin out the...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "5672  8095  ...      1\n",
              "2719  3905  ...      1\n",
              "3739  5315  ...      0\n",
              "6209  8859  ...      0\n",
              "1009  1464  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "QoAaFxpTjdW_",
        "outputId": "675e7809-95f8-4d9c-f515-2650b095c8ae"
      },
      "source": [
        "def remove_emoji(text):\n",
        "    emoji_pattern = re.compile(\"[\"\n",
        "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "                           u\"\\U00002702-\\U000027B0\"\n",
        "                           u\"\\U000024C2-\\U0001F251\"\n",
        "                           \"]+\", flags=re.UNICODE)\n",
        "    return emoji_pattern.sub(r'', text)\n",
        "\n",
        "train['text']=train['text'].apply(lambda x: remove_emoji(x))\n",
        "train.sample(5)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6102</th>\n",
              "      <td>8712</td>\n",
              "      <td>sinking</td>\n",
              "      <td>nan</td>\n",
              "      <td>the sinking ship sinkingshipindy scarlet lane ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2928</th>\n",
              "      <td>4209</td>\n",
              "      <td>drowned</td>\n",
              "      <td>nan</td>\n",
              "      <td>abcnews24 peterdutton_mp he also told you no ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3345</th>\n",
              "      <td>4789</td>\n",
              "      <td>evacuated</td>\n",
              "      <td>benton city washington</td>\n",
              "      <td>our thoughts are with these local residents ti...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4775</th>\n",
              "      <td>6794</td>\n",
              "      <td>lightning</td>\n",
              "      <td>state college pa</td>\n",
              "      <td>check out this amazing footage of lightning fi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4433</th>\n",
              "      <td>6306</td>\n",
              "      <td>hostage</td>\n",
              "      <td></td>\n",
              "      <td>who s that shadow holdin me hostage i ve been ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id    keyword  ...                                               text target\n",
              "6102  8712    sinking  ...  the sinking ship sinkingshipindy scarlet lane ...      0\n",
              "2928  4209    drowned  ...   abcnews24 peterdutton_mp he also told you no ...      0\n",
              "3345  4789  evacuated  ...  our thoughts are with these local residents ti...      1\n",
              "4775  6794  lightning  ...  check out this amazing footage of lightning fi...      0\n",
              "4433  6306    hostage  ...  who s that shadow holdin me hostage i ve been ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcr9i7wojdZT",
        "outputId": "8d68887f-728f-4e5c-b615-9ffc8ef42ea3"
      },
      "source": [
        "!pip install pyspellchecker"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspellchecker\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/c7/435f49c0ac6bec031d1aba4daf94dc21dc08a9db329692cdb77faac51cea/pyspellchecker-0.6.2-py3-none-any.whl (2.7MB)\n",
            "\u001b[K     |████████████████████████████████| 2.7MB 5.7MB/s \n",
            "\u001b[?25hInstalling collected packages: pyspellchecker\n",
            "Successfully installed pyspellchecker-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTusYHGwj5wI"
      },
      "source": [
        "from spellchecker import SpellChecker\n",
        "\n",
        "spell = SpellChecker()\n",
        "def correct_spellings(text):\n",
        "    corrected_text = []\n",
        "    misspelled_words = spell.unknown(text.split())\n",
        "    for word in text.split():\n",
        "        if word in misspelled_words:\n",
        "            corrected_text.append(spell.correction(word))\n",
        "        else:\n",
        "            corrected_text.append(word)\n",
        "    return \" \".join(corrected_text)\n",
        "\n",
        "#train['text']=train['text'].apply(lambda x : correct_spellings(x))\n",
        "#train.sample(5)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JYQw0D2aj5yO",
        "outputId": "010209a6-249f-4853-c6f4-87d9e8437b84"
      },
      "source": [
        "text = 'corrrect me pleas. MY NLP preject is due tomrow'\n",
        "correct_spellings(text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'correct me please MY NLP project is due tomorow'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2hEPNOLj50i"
      },
      "source": [
        "## Replacing common acronyms\n",
        "\n",
        "def other_clean(text):\n",
        "        \"\"\"\n",
        "            Other manual text cleaning techniques\n",
        "        \"\"\"\n",
        "        # Typos, slang and other\n",
        "        sample_typos_slang = {\n",
        "                                \"w/e\": \"whatever\",\n",
        "                                \"usagov\": \"usa government\",\n",
        "                                \"recentlu\": \"recently\",\n",
        "                                \"ph0tos\": \"photos\",\n",
        "                                \"amirite\": \"am i right\",\n",
        "                                \"exp0sed\": \"exposed\",\n",
        "                                \"<3\": \"love\",\n",
        "                                \"luv\": \"love\",\n",
        "                                \"amageddon\": \"armageddon\",\n",
        "                                \"trfc\": \"traffic\",\n",
        "                                \"16yr\": \"16 year\"\n",
        "                                }\n",
        "\n",
        "        # Acronyms\n",
        "        sample_acronyms =  { \n",
        "                            \"mh370\": \"malaysia airlines flight 370\",\n",
        "                            \"okwx\": \"oklahoma city weather\",\n",
        "                            \"arwx\": \"arkansas weather\",    \n",
        "                            \"gawx\": \"georgia weather\",  \n",
        "                            \"scwx\": \"south carolina weather\",  \n",
        "                            \"cawx\": \"california weather\",\n",
        "                            \"tnwx\": \"tennessee weather\",\n",
        "                            \"azwx\": \"arizona weather\",  \n",
        "                            \"alwx\": \"alabama weather\",\n",
        "                            \"usnwsgov\": \"united states national weather service\",\n",
        "                            \"2mw\": \"tomorrow\"\n",
        "                            }\n",
        "\n",
        "        \n",
        "        # Some common abbreviations \n",
        "        sample_abbr = {\n",
        "                        \"$\" : \" dollar \",\n",
        "                        \"€\" : \" euro \",\n",
        "                        \"4ao\" : \"for adults only\",\n",
        "                        \"a.m\" : \"before midday\",\n",
        "                        \"a3\" : \"anytime anywhere anyplace\",\n",
        "                        \"aamof\" : \"as a matter of fact\",\n",
        "                        \"acct\" : \"account\",\n",
        "                        \"adih\" : \"another day in hell\",\n",
        "                        \"afaic\" : \"as far as i am concerned\",\n",
        "                        \"afaict\" : \"as far as i can tell\",\n",
        "                        \"afaik\" : \"as far as i know\",\n",
        "                        \"afair\" : \"as far as i remember\",\n",
        "                        \"afk\" : \"away from keyboard\",\n",
        "                        \"app\" : \"application\",\n",
        "                        \"approx\" : \"approximately\",\n",
        "                        \"apps\" : \"applications\",\n",
        "                        \"asap\" : \"as soon as possible\",\n",
        "                        \"asl\" : \"age, sex, location\",\n",
        "                        \"atk\" : \"at the keyboard\",\n",
        "                        \"ave.\" : \"avenue\",\n",
        "                        \"aymm\" : \"are you my mother\",\n",
        "                        \"ayor\" : \"at your own risk\", \n",
        "                        \"b&b\" : \"bed and breakfast\",\n",
        "                        \"b+b\" : \"bed and breakfast\",\n",
        "                        \"b.c\" : \"before christ\",\n",
        "                        \"b2b\" : \"business to business\",\n",
        "                        \"b2c\" : \"business to customer\",\n",
        "                        \"b4\" : \"before\",\n",
        "                        \"b4n\" : \"bye for now\",\n",
        "                        \"b@u\" : \"back at you\",\n",
        "                        \"bae\" : \"before anyone else\",\n",
        "                        \"bak\" : \"back at keyboard\",\n",
        "                        \"bbbg\" : \"bye bye be good\",\n",
        "                        \"bbc\" : \"british broadcasting corporation\",\n",
        "                        \"bbias\" : \"be back in a second\",\n",
        "                        \"bbl\" : \"be back later\",\n",
        "                        \"bbs\" : \"be back soon\",\n",
        "                        \"be4\" : \"before\",\n",
        "                        \"bfn\" : \"bye for now\",\n",
        "                        \"blvd\" : \"boulevard\",\n",
        "                        \"bout\" : \"about\",\n",
        "                        \"brb\" : \"be right back\",\n",
        "                        \"bros\" : \"brothers\",\n",
        "                        \"brt\" : \"be right there\",\n",
        "                        \"bsaaw\" : \"big smile and a wink\",\n",
        "                        \"btw\" : \"by the way\",\n",
        "                        \"bwl\" : \"bursting with laughter\",\n",
        "                        \"c/o\" : \"care of\",\n",
        "                        \"cet\" : \"central european time\",\n",
        "                        \"cf\" : \"compare\",\n",
        "                        \"cia\" : \"central intelligence agency\",\n",
        "                        \"csl\" : \"can not stop laughing\",\n",
        "                        \"cu\" : \"see you\",\n",
        "                        \"cul8r\" : \"see you later\",\n",
        "                        \"cv\" : \"curriculum vitae\",\n",
        "                        \"cwot\" : \"complete waste of time\",\n",
        "                        \"cya\" : \"see you\",\n",
        "                        \"cyt\" : \"see you tomorrow\",\n",
        "                        \"dae\" : \"does anyone else\",\n",
        "                        \"dbmib\" : \"do not bother me i am busy\",\n",
        "                        \"diy\" : \"do it yourself\",\n",
        "                        \"dm\" : \"direct message\",\n",
        "                        \"dwh\" : \"during work hours\",\n",
        "                        \"e123\" : \"easy as one two three\",\n",
        "                        \"eet\" : \"eastern european time\",\n",
        "                        \"eg\" : \"example\",\n",
        "                        \"embm\" : \"early morning business meeting\",\n",
        "                        \"encl\" : \"enclosed\",\n",
        "                        \"encl.\" : \"enclosed\",\n",
        "                        \"etc\" : \"and so on\",\n",
        "                        \"faq\" : \"frequently asked questions\",\n",
        "                        \"fawc\" : \"for anyone who cares\",\n",
        "                        \"fb\" : \"facebook\",\n",
        "                        \"fc\" : \"fingers crossed\",\n",
        "                        \"fig\" : \"figure\",\n",
        "                        \"fimh\" : \"forever in my heart\", \n",
        "                        \"ft.\" : \"feet\",\n",
        "                        \"ft\" : \"featuring\",\n",
        "                        \"ftl\" : \"for the loss\",\n",
        "                        \"ftw\" : \"for the win\",\n",
        "                        \"fwiw\" : \"for what it is worth\",\n",
        "                        \"fyi\" : \"for your information\",\n",
        "                        \"g9\" : \"genius\",\n",
        "                        \"gahoy\" : \"get a hold of yourself\",\n",
        "                        \"gal\" : \"get a life\",\n",
        "                        \"gcse\" : \"general certificate of secondary education\",\n",
        "                        \"gfn\" : \"gone for now\",\n",
        "                        \"gg\" : \"good game\",\n",
        "                        \"gl\" : \"good luck\",\n",
        "                        \"glhf\" : \"good luck have fun\",\n",
        "                        \"gmt\" : \"greenwich mean time\",\n",
        "                        \"gmta\" : \"great minds think alike\",\n",
        "                        \"gn\" : \"good night\",\n",
        "                        \"g.o.a.t\" : \"greatest of all time\",\n",
        "                        \"goat\" : \"greatest of all time\",\n",
        "                        \"goi\" : \"get over it\",\n",
        "                        \"gps\" : \"global positioning system\",\n",
        "                        \"gr8\" : \"great\",\n",
        "                        \"gratz\" : \"congratulations\",\n",
        "                        \"gyal\" : \"girl\",\n",
        "                        \"h&c\" : \"hot and cold\",\n",
        "                        \"hp\" : \"horsepower\",\n",
        "                        \"hr\" : \"hour\",\n",
        "                        \"hrh\" : \"his royal highness\",\n",
        "                        \"ht\" : \"height\",\n",
        "                        \"ibrb\" : \"i will be right back\",\n",
        "                        \"ic\" : \"i see\",\n",
        "                        \"icq\" : \"i seek you\",\n",
        "                        \"icymi\" : \"in case you missed it\",\n",
        "                        \"idc\" : \"i do not care\",\n",
        "                        \"idgadf\" : \"i do not give a damn fuck\",\n",
        "                        \"idgaf\" : \"i do not give a fuck\",\n",
        "                        \"idk\" : \"i do not know\",\n",
        "                        \"ie\" : \"that is\",\n",
        "                        \"i.e\" : \"that is\",\n",
        "                        \"ifyp\" : \"i feel your pain\",\n",
        "                        \"IG\" : \"instagram\",\n",
        "                        \"iirc\" : \"if i remember correctly\",\n",
        "                        \"ilu\" : \"i love you\",\n",
        "                        \"ily\" : \"i love you\",\n",
        "                        \"imho\" : \"in my humble opinion\",\n",
        "                        \"imo\" : \"in my opinion\",\n",
        "                        \"imu\" : \"i miss you\",\n",
        "                        \"iow\" : \"in other words\",\n",
        "                        \"irl\" : \"in real life\",\n",
        "                        \"j4f\" : \"just for fun\",\n",
        "                        \"jic\" : \"just in case\",\n",
        "                        \"jk\" : \"just kidding\",\n",
        "                        \"jsyk\" : \"just so you know\",\n",
        "                        \"l8r\" : \"later\",\n",
        "                        \"lb\" : \"pound\",\n",
        "                        \"lbs\" : \"pounds\",\n",
        "                        \"ldr\" : \"long distance relationship\",\n",
        "                        \"lmao\" : \"laugh my ass off\",\n",
        "                        \"lmfao\" : \"laugh my fucking ass off\",\n",
        "                        \"lol\" : \"laughing out loud\",\n",
        "                        \"ltd\" : \"limited\",\n",
        "                        \"ltns\" : \"long time no see\",\n",
        "                        \"m8\" : \"mate\",\n",
        "                        \"mf\" : \"motherfucker\",\n",
        "                        \"mfs\" : \"motherfuckers\",\n",
        "                        \"mfw\" : \"my face when\",\n",
        "                        \"mofo\" : \"motherfucker\",\n",
        "                        \"mph\" : \"miles per hour\",\n",
        "                        \"mr\" : \"mister\",\n",
        "                        \"mrw\" : \"my reaction when\",\n",
        "                        \"ms\" : \"miss\",\n",
        "                        \"mte\" : \"my thoughts exactly\",\n",
        "                        \"nagi\" : \"not a good idea\",\n",
        "                        \"nbc\" : \"national broadcasting company\",\n",
        "                        \"nbd\" : \"not big deal\",\n",
        "                        \"nfs\" : \"not for sale\",\n",
        "                        \"ngl\" : \"not going to lie\",\n",
        "                        \"nhs\" : \"national health service\",\n",
        "                        \"nrn\" : \"no reply necessary\",\n",
        "                        \"nsfl\" : \"not safe for life\",\n",
        "                        \"nsfw\" : \"not safe for work\",\n",
        "                        \"nth\" : \"nice to have\",\n",
        "                        \"nvr\" : \"never\",\n",
        "                        \"nyc\" : \"new york city\",\n",
        "                        \"oc\" : \"original content\",\n",
        "                        \"og\" : \"original\",\n",
        "                        \"ohp\" : \"overhead projector\",\n",
        "                        \"oic\" : \"oh i see\",\n",
        "                        \"omdb\" : \"over my dead body\",\n",
        "                        \"omg\" : \"oh my god\",\n",
        "                        \"omw\" : \"on my way\",\n",
        "                        \"p.a\" : \"per annum\",\n",
        "                        \"p.m\" : \"after midday\",\n",
        "                        \"pm\" : \"prime minister\",\n",
        "                        \"poc\" : \"people of color\",\n",
        "                        \"pov\" : \"point of view\",\n",
        "                        \"pp\" : \"pages\",\n",
        "                        \"ppl\" : \"people\",\n",
        "                        \"prw\" : \"parents are watching\",\n",
        "                        \"ps\" : \"postscript\",\n",
        "                        \"pt\" : \"point\",\n",
        "                        \"ptb\" : \"please text back\",\n",
        "                        \"pto\" : \"please turn over\",\n",
        "                        \"qpsa\" : \"what happens\", #\"que pasa\",\n",
        "                        \"ratchet\" : \"rude\",\n",
        "                        \"rbtl\" : \"read between the lines\",\n",
        "                        \"rlrt\" : \"real life retweet\", \n",
        "                        \"rofl\" : \"rolling on the floor laughing\",\n",
        "                        \"roflol\" : \"rolling on the floor laughing out loud\",\n",
        "                        \"rotflmao\" : \"rolling on the floor laughing my ass off\",\n",
        "                        \"rt\" : \"retweet\",\n",
        "                        \"ruok\" : \"are you ok\",\n",
        "                        \"sfw\" : \"safe for work\",\n",
        "                        \"sk8\" : \"skate\",\n",
        "                        \"smh\" : \"shake my head\",\n",
        "                        \"sq\" : \"square\",\n",
        "                        \"srsly\" : \"seriously\", \n",
        "                        \"ssdd\" : \"same stuff different day\",\n",
        "                        \"tbh\" : \"to be honest\",\n",
        "                        \"tbs\" : \"tablespooful\",\n",
        "                        \"tbsp\" : \"tablespooful\",\n",
        "                        \"tfw\" : \"that feeling when\",\n",
        "                        \"thks\" : \"thank you\",\n",
        "                        \"tho\" : \"though\",\n",
        "                        \"thx\" : \"thank you\",\n",
        "                        \"tia\" : \"thanks in advance\",\n",
        "                        \"til\" : \"today i learned\",\n",
        "                        \"tl;dr\" : \"too long i did not read\",\n",
        "                        \"tldr\" : \"too long i did not read\",\n",
        "                        \"tmb\" : \"tweet me back\",\n",
        "                        \"tntl\" : \"trying not to laugh\",\n",
        "                        \"ttyl\" : \"talk to you later\",\n",
        "                        \"u\" : \"you\",\n",
        "                        \"u2\" : \"you too\",\n",
        "                        \"u4e\" : \"yours for ever\",\n",
        "                        \"utc\" : \"coordinated universal time\",\n",
        "                        \"w/\" : \"with\",\n",
        "                        \"w/o\" : \"without\",\n",
        "                        \"w8\" : \"wait\",\n",
        "                        \"wassup\" : \"what is up\",\n",
        "                        \"wb\" : \"welcome back\",\n",
        "                        \"wtf\" : \"what the fuck\",\n",
        "                        \"wtg\" : \"way to go\",\n",
        "                        \"wtpa\" : \"where the party at\",\n",
        "                        \"wuf\" : \"where are you from\",\n",
        "                        \"wuzup\" : \"what is up\",\n",
        "                        \"wywh\" : \"wish you were here\",\n",
        "                        \"yd\" : \"yard\",\n",
        "                        \"ygtr\" : \"you got that right\",\n",
        "                        \"ynk\" : \"you never know\",\n",
        "                        \"zzz\" : \"sleeping bored and tired\"\n",
        "                        }\n",
        "            \n",
        "        sample_typos_slang_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_typos_slang.keys()) + r')(?!\\w)')\n",
        "        sample_acronyms_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_acronyms.keys()) + r')(?!\\w)')\n",
        "        sample_abbr_pattern = re.compile(r'(?<!\\w)(' + '|'.join(re.escape(key) for key in sample_abbr.keys()) + r')(?!\\w)')\n",
        "        \n",
        "        text = sample_typos_slang_pattern.sub(lambda x: sample_typos_slang[x.group()], text)\n",
        "        text = sample_acronyms_pattern.sub(lambda x: sample_acronyms[x.group()], text)\n",
        "        text = sample_abbr_pattern.sub(lambda x: sample_abbr[x.group()], text)\n",
        "        \n",
        "        return text"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "EXhuQe_XkK2z",
        "outputId": "2c0ae861-894d-495c-82df-2565af88005a"
      },
      "source": [
        "## !Need to change variable names and abbrevations as appropriate\n",
        "train[\"text\"] = train[\"text\"].apply(lambda x: other_clean(x))\n",
        "train.sample(5)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3328</th>\n",
              "      <td>4768</td>\n",
              "      <td>evacuated</td>\n",
              "      <td>portland oregon</td>\n",
              "      <td>red cross re opens shelter at bickleton school...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5294</th>\n",
              "      <td>7561</td>\n",
              "      <td>outbreak</td>\n",
              "      <td>united states</td>\n",
              "      <td>families to sue over legionnaires more than 40...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>907</th>\n",
              "      <td>1312</td>\n",
              "      <td>bloody</td>\n",
              "      <td>singapore</td>\n",
              "      <td>eh hello cover your bloody thighs your bloody ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3266</th>\n",
              "      <td>4691</td>\n",
              "      <td>engulfed</td>\n",
              "      <td>nan</td>\n",
              "      <td>he came to a land which was engulfed in tribal...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1853</th>\n",
              "      <td>2664</td>\n",
              "      <td>crush</td>\n",
              "      <td>nan</td>\n",
              "      <td>ina buted girl crush</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id    keyword  ...                                               text target\n",
              "3328  4768  evacuated  ...  red cross re opens shelter at bickleton school...      1\n",
              "5294  7561   outbreak  ...  families to sue over legionnaires more than 40...      1\n",
              "907   1312     bloody  ...  eh hello cover your bloody thighs your bloody ...      0\n",
              "3266  4691   engulfed  ...  he came to a land which was engulfed in tribal...      0\n",
              "1853  2664      crush  ...                              ina buted girl crush       1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJFG-NYzkK6S"
      },
      "source": [
        "## Removing single characters\n",
        "train[\"text\"] = train[\"text\"].str.replace(r'\\b\\w\\b','').str.replace(r'\\s+', ' ')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hdcs8qPIn1D_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d4c1e1f-a2de-403e-94a1-89c5492bfcef"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA7F95bp9g3-"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop = stopwords.words('english')\n",
        "def tokenizer(text):\n",
        "    tokenized = []\n",
        "    for string in text:\n",
        "        string = re.sub('[^a-z\\sA-Z]', '', string)\n",
        "        # get rid of all the http syntax\n",
        "        string = re.sub('http\\S+', '', string)\n",
        "        tokenized.append([w for w in string.split() if w not in stop])\n",
        "    return tokenized"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InA0iUEGnkPN"
      },
      "source": [
        "train['tokenized'] = tokenizer(train[\"text\"])"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYBuqfVnn4Qr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "f3c3cc58-7b38-4a9c-cf28-99aac9a0cb88"
      },
      "source": [
        "train.sample(5)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>tokenized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3262</th>\n",
              "      <td>4687</td>\n",
              "      <td>engulfed</td>\n",
              "      <td>london</td>\n",
              "      <td>suelinflower there is no words to describe th...</td>\n",
              "      <td>0</td>\n",
              "      <td>[suelinflower, words, describe, physical, pain...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4611</th>\n",
              "      <td>6554</td>\n",
              "      <td>injury</td>\n",
              "      <td>nan</td>\n",
              "      <td>dante exum knee injury could stem jazz hoped f...</td>\n",
              "      <td>1</td>\n",
              "      <td>[dante, exum, knee, injury, could, stem, jazz,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1080</th>\n",
              "      <td>1560</td>\n",
              "      <td>bomb</td>\n",
              "      <td>lagos nigeria</td>\n",
              "      <td>if fall is men god praiz8 is bomb well av alwa...</td>\n",
              "      <td>1</td>\n",
              "      <td>[fall, men, god, praiz, bomb, well, av, always...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7423</th>\n",
              "      <td>10620</td>\n",
              "      <td>wounded</td>\n",
              "      <td>nan</td>\n",
              "      <td>police officer wounded suspect dead after exch...</td>\n",
              "      <td>1</td>\n",
              "      <td>[police, officer, wounded, suspect, dead, exch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1456</th>\n",
              "      <td>2099</td>\n",
              "      <td>casualty</td>\n",
              "      <td>nan</td>\n",
              "      <td>casualty insurance jobs against hunt up willin...</td>\n",
              "      <td>0</td>\n",
              "      <td>[casualty, insurance, jobs, hunt, willingheart...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id   keyword  ... target                                          tokenized\n",
              "3262   4687  engulfed  ...      0  [suelinflower, words, describe, physical, pain...\n",
              "4611   6554    injury  ...      1  [dante, exum, knee, injury, could, stem, jazz,...\n",
              "1080   1560      bomb  ...      1  [fall, men, god, praiz, bomb, well, av, always...\n",
              "7423  10620   wounded  ...      1  [police, officer, wounded, suspect, dead, exch...\n",
              "1456   2099  casualty  ...      0  [casualty, insurance, jobs, hunt, willingheart...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbkkU1Fjo8o9"
      },
      "source": [
        "# Performing stemming\n",
        "\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA3wSqdSp-p5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32940b1c-673c-435c-a2aa-ae9d19227b42"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7eOzoOwpZTp"
      },
      "source": [
        "def stem(unstemmed_list):  \n",
        "  ps = PorterStemmer()\n",
        "\n",
        "  final_stemmed_list = []\n",
        "\n",
        "  for i in range(len(unstemmed_list)):\n",
        "    sentence = unstemmed_list[i]\n",
        "    #print(sentence)\n",
        "    words = word_tokenize(sentence)\n",
        "    stemmed_list = []\n",
        "    for w in words:\n",
        "        stemmed_list.append(ps.stem(w))\n",
        "    stemmed_list = ' '.join(stemmed_list)\n",
        "    final_stemmed_list.append(stemmed_list)\n",
        "\n",
        "  return final_stemmed_list\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX6jvSfdrkbX"
      },
      "source": [
        "unstemmed_list = train['text'].tolist()\n",
        "train['stemmed_text'] = stem(unstemmed_list)\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8KYRf1trkdo"
      },
      "source": [
        "#Removing digits\n",
        "train['stemmed_text'] = train['stemmed_text'].str.replace('\\d+', '')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iatokNiHsBcZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "10e3eec5-bd72-453e-a4f0-d5984923074e"
      },
      "source": [
        "train.sample(5)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>tokenized</th>\n",
              "      <th>stemmed_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6610</th>\n",
              "      <td>9466</td>\n",
              "      <td>terrorism</td>\n",
              "      <td>nan</td>\n",
              "      <td>dhs refuses to call chattanooga islamic terror...</td>\n",
              "      <td>1</td>\n",
              "      <td>[dhs, refuses, call, chattanooga, islamic, ter...</td>\n",
              "      <td>dh refus to call chattanooga islam terror ûª o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2849</th>\n",
              "      <td>4095</td>\n",
              "      <td>displaced</td>\n",
              "      <td>palestine</td>\n",
              "      <td>cityofhummus ilnewsflash do you want to hear ...</td>\n",
              "      <td>0</td>\n",
              "      <td>[cityofhummus, ilnewsflash, want, hear, displa...</td>\n",
              "      <td>cityofhummu ilnewsflash do you want to hear mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>397</td>\n",
              "      <td>apocalypse</td>\n",
              "      <td>sindria</td>\n",
              "      <td>ohh no fukurodani didn survive the apocalypse ...</td>\n",
              "      <td>1</td>\n",
              "      <td>[ohh, fukurodani, survive, apocalypse, bokuto,...</td>\n",
              "      <td>ohh no fukurodani didn surviv the apocalyps bo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6346</th>\n",
              "      <td>9075</td>\n",
              "      <td>structural 20failure</td>\n",
              "      <td>nan</td>\n",
              "      <td>investigators have said virgin galactic spaces...</td>\n",
              "      <td>1</td>\n",
              "      <td>[investigators, said, virgin, galactic, spaces...</td>\n",
              "      <td>investig have said virgin galact spaceship cra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5729</th>\n",
              "      <td>8176</td>\n",
              "      <td>rescuers</td>\n",
              "      <td>washington</td>\n",
              "      <td>news many deaths in shipwreck rescuers are tr...</td>\n",
              "      <td>1</td>\n",
              "      <td>[news, many, deaths, shipwreck, rescuers, tryi...</td>\n",
              "      <td>news mani death in shipwreck rescuer are tri t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...                                       stemmed_text\n",
              "6610  9466  ...  dh refus to call chattanooga islam terror ûª o...\n",
              "2849  4095  ...  cityofhummu ilnewsflash do you want to hear mo...\n",
              "273    397  ...  ohh no fukurodani didn surviv the apocalyps bo...\n",
              "6346  9075  ...  investig have said virgin galact spaceship cra...\n",
              "5729  8176  ...  news mani death in shipwreck rescuer are tri t...\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jon1sPtHsBeo"
      },
      "source": [
        "# Data visualization imports\n",
        "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# importing images\n",
        "from google.colab import files\n",
        "from IPython.display import Image\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "qgRhlTVEjQ8W",
        "outputId": "96f90b21-6fc0-4c0e-99ef-0768641a38f2"
      },
      "source": [
        "twitter_image = files.upload()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-901ac520-04ad-4577-b28a-0a7add95fb03\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-901ac520-04ad-4577-b28a-0a7add95fb03\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-6323045410e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtwitter_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m   result = _output.eval_js(\n\u001b[1;32m     63\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[0;32m---> 64\u001b[0;31m           input_id=input_id, output_id=output_id))\n\u001b[0m\u001b[1;32m     65\u001b[0m   \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_collections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_six\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJUVSCFtpZWC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "586169e9-3853-4b78-9652-5abf023279e4"
      },
      "source": [
        "# word cloud of keywords for both classes (starts)\n",
        "disaster_tweets = train.groupby(\"target\")\n",
        "\n",
        "disaster_tweets.describe().head()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr th {\n",
              "        text-align: left;\n",
              "    }\n",
              "\n",
              "    .dataframe thead tr:last-of-type th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th colspan=\"4\" halign=\"left\">id</th>\n",
              "      <th colspan=\"4\" halign=\"left\">keyword</th>\n",
              "      <th colspan=\"4\" halign=\"left\">location</th>\n",
              "      <th colspan=\"4\" halign=\"left\">text</th>\n",
              "      <th colspan=\"4\" halign=\"left\">tokenized</th>\n",
              "      <th colspan=\"4\" halign=\"left\">stemmed_text</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4342</td>\n",
              "      <td>4342</td>\n",
              "      <td>480</td>\n",
              "      <td>1</td>\n",
              "      <td>4342</td>\n",
              "      <td>219</td>\n",
              "      <td>body 20bags</td>\n",
              "      <td>40</td>\n",
              "      <td>4342</td>\n",
              "      <td>2037</td>\n",
              "      <td>nan</td>\n",
              "      <td>1458</td>\n",
              "      <td>4342</td>\n",
              "      <td>4311</td>\n",
              "      <td>the prophet peace be upon him said save yourse...</td>\n",
              "      <td>4</td>\n",
              "      <td>4342</td>\n",
              "      <td>4288</td>\n",
              "      <td>[black, eye, space, battle, occurred, star, in...</td>\n",
              "      <td>8</td>\n",
              "      <td>4342</td>\n",
              "      <td>4293</td>\n",
              "      <td>black eye space battl occur at star o involv f...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3271</td>\n",
              "      <td>3271</td>\n",
              "      <td>2189</td>\n",
              "      <td>1</td>\n",
              "      <td>3271</td>\n",
              "      <td>221</td>\n",
              "      <td>nan</td>\n",
              "      <td>42</td>\n",
              "      <td>3271</td>\n",
              "      <td>1418</td>\n",
              "      <td>nan</td>\n",
              "      <td>1075</td>\n",
              "      <td>3271</td>\n",
              "      <td>3203</td>\n",
              "      <td>11 year old boy charged with manslaughter of t...</td>\n",
              "      <td>10</td>\n",
              "      <td>3271</td>\n",
              "      <td>3202</td>\n",
              "      <td>[year, old, boy, charged, manslaughter, toddle...</td>\n",
              "      <td>10</td>\n",
              "      <td>3271</td>\n",
              "      <td>3202</td>\n",
              "      <td>year old boy charg with manslaught of toddler...</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          id         ...                                       stemmed_text     \n",
              "       count unique  ...                                                top freq\n",
              "target               ...                                                        \n",
              "0       4342   4342  ...  black eye space battl occur at star o involv f...    7\n",
              "1       3271   3271  ...   year old boy charg with manslaught of toddler...   10\n",
              "\n",
              "[2 rows x 24 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajU9IHv0n4TR"
      },
      "source": [
        "# divide disaster tweets by text\n",
        "disaster_tweets = train[train['target'] == '1'].text\n",
        "disaster_tweets = \" \".join(line for line in disaster_tweets)\n",
        "\n",
        "non_disaster_tweets = train[train['target'] == '0'].text\n",
        "non_disaster_tweets = \" \".join(line for line in non_disaster_tweets)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y65zzBmCg9UV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "outputId": "21668a59-e991-436d-b390-a0fd76e7ce0e"
      },
      "source": [
        "# Setting mask for wordcloud.\n",
        "from PIL import Image\n",
        "twitter_mask = np.array(Image.open('twitter_mask.png'))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-dd4f9d19be34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Setting mask for wordcloud.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtwitter_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'twitter_mask.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'twitter_mask.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdDawRsKm_t1"
      },
      "source": [
        "# Function: plot_wordcloud\n",
        "# Params: title (str) - title for the wordcloud,\n",
        "#         text (str) - joined text to display\n",
        "#         background_color (str) - \"white\", \"black\"\n",
        "# Does: plots the wordcloud\n",
        "def plot_wordcloud(title, text, background_color):\n",
        "  stopwords = set(STOPWORDS)\n",
        "  # update stowords (if needed)\n",
        "  stopwords.update([\"https\", \"co\", \"__\", \"amp\", \"û\", \"will\", \"new\", \"I\"])\n",
        "\n",
        "\n",
        "  wordcloud = WordCloud(mask=twitter_mask, stopwords=stopwords, background_color=background_color,\n",
        "                        width=1800, height=1400).generate(text)\n",
        "  plt.figure(figsize=(20,10))\n",
        "  plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.tight_layout(pad=0)\n",
        "\n",
        "  plt.title(title,\n",
        "              fontdict={\n",
        "                  'size': 20,\n",
        "                  'verticalalignment': 'bottom'\n",
        "              })\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKPtskMleVwL"
      },
      "source": [
        "plot_wordcloud(\"Most common words in disaster tweets\", disaster_tweets, \"black\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enp_UyDbnkRw"
      },
      "source": [
        "plot_wordcloud(\"Most common words in non-disaster tweets\", non_disaster_tweets, \"white\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2_JuBPRka3q"
      },
      "source": [
        "disaster tweets have much more specific terms like \"malaysian airlines\", \"norther california\". \n",
        "\n",
        "non-disaster tweet terms are more general like \"people\", \"day\", \"game\"..\n",
        "\n",
        "\n",
        "Some common words involved links (which is added in stopwords becauset they are irrelevant).\n",
        "Still looking for ways to get rid of \"__\" and \"u hat\".\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNdRZ0bYbE7I"
      },
      "source": [
        "Doc2Vec build vector embeddings for each document in data. \n",
        "(developed by same creators of word2vec)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1fEunQ4gZqS"
      },
      "source": [
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "from tqdm import tqdm "
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuux5O-pr2Dw"
      },
      "source": [
        "\n",
        "# Function: classify_doc2vec\n",
        "# Params: train and test dataframe (each with \"stemmed_text\" and \"target\" column)\n",
        "#         n - (odd integer) number of most similar vectors for classification\n",
        "# Returns: classification of test dataset (list)\n",
        "# Does: classify all the test tweets based on doc2vec modeling\n",
        "#       finds n most similar documents from train dataset and classify based on majority\n",
        "def classify_doc2vec(train, test, n):\n",
        "  # prepare all the tokens and classifications fror modeling \n",
        "  test_x = list(tokenizer(test[\"stemmed_text\"]))\n",
        "  train_x = list(tokenizer(train[\"stemmed_text\"]))\n",
        "  train_y = list(train[\"target\"])\n",
        "\n",
        "  # tag the document and model (use devset to tune the params)\n",
        "  # model - using distributed bag of words version\n",
        "  # larger vectors give more accurate results (vector size = 1000, give 70% accuracy)\n",
        "  tagged_docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_x)]\n",
        "  model = Doc2Vec(tagged_docs, vector_size=1000, dm = 0, window=7, min_count=1, epochs = 100)\n",
        "  \n",
        "  # get the most similar vectors for each text in testset and classify them by majority\n",
        "  # ex. if 3/5 similar vectors were classified as disaster tweet, that tweet is a disaster tweets\n",
        "  \n",
        "  pred_y = []\n",
        "  for text in tqdm(test_x):\n",
        "    v = model.infer_vector(text, steps = 100)\n",
        "    similar_vectors = model.docvecs.most_similar([v], topn = n)\n",
        "\n",
        "    class_dic = {'1': 0, '0': 0} \n",
        "    for i, j in similar_vectors:\n",
        "      pred = train_y[i]\n",
        "      class_dic[pred] += 1 \n",
        "    \n",
        "    if (class_dic['1'] > class_dic['0']):\n",
        "      pred_y.append('1')\n",
        "    else:\n",
        "      pred_y.append('0')\n",
        "\n",
        "  return pred_y\n",
        "\n",
        "# Function: evaluate pred\n",
        "# params: expected (correct classification), real (prediction)\n",
        "#         both should be 'list' type and \n",
        "#         elements should be string (so '1' not integer 1)\n",
        "# Returns: dictionary of accuracy, precision, recall, and f1\n",
        "# followed formulas here: https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/\n",
        "def evaluate_pred(expected, pred):\n",
        "  # true positive (TP): expected = '1', pred = '1'\n",
        "  # false negative (FN): expected = '1', pred = '0'\n",
        "  # false positive (FP): expected = '0', pred = '1'\n",
        "  # true negative (TN): expected = '0', pred = '0'\n",
        "  TP = 0\n",
        "  FN = 0\n",
        "  FP = 0\n",
        "  TN = 0\n",
        "\n",
        "  if len(pred) != len(expected):\n",
        "    print(\"The number of predictions are not equal to number of expected\")\n",
        "    assert 1 == 2\n",
        "\n",
        "  for i in range(len(pred)):\n",
        "    e = expected[i]\n",
        "    p = pred[i]\n",
        "    if e == '1':\n",
        "      if p == '1':\n",
        "        TP += 1\n",
        "      else:\n",
        "        FN += 1\n",
        "    else:\n",
        "      if p == '1':\n",
        "        FP += 1\n",
        "      else:\n",
        "        TN += 1\n",
        "\n",
        "  # accuracy = correct predictions over total (disaster tweets + non-disaster tweets)\n",
        "  # Precision = correct disaster predictions / total predicted disaster tweets\n",
        "  # Recall = correct disaster predictions / total actual disaster tweets \n",
        "  # F1 = harmonic mean of precision and recall \n",
        "  accuracy = (TP + TN) / len(pred)\n",
        "  precision = TP / (TP + FP)\n",
        "  recall = TP / (TP + FN)\n",
        "  F1 = 2 * (recall * precision) / (recall + precision)\n",
        "\n",
        "  return {'accuracy': accuracy, 'precision': precision, 'recall': recall, 'F1': F1}\n",
        "\n",
        "\n"
      ],
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFdjIRy94dYb",
        "outputId": "4dd8ca82-a18d-4edb-e018-83b470e21f9b"
      },
      "source": [
        "# test on dev set \n",
        "dev_set = train.iloc[:1500]\n",
        "train_set = train.iloc[1500:]\n",
        "\n",
        "# changing numbers of topn didn't change accuracy that much\n",
        "# greater vector size and epoch affected accuracy way more\n",
        "# generally better with recall than precision \n",
        "pred = classify_doc2vec(train_set, dev_set, 5)\n",
        "evaluate_pred(list(dev_set['target']), pred)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1500/1500 [00:16<00:00, 91.79it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'F1': 0.6321243523316062,\n",
              " 'accuracy': 0.716,\n",
              " 'precision': 0.6110183639398998,\n",
              " 'recall': 0.6547406082289803}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFHrmgHxW-N_",
        "outputId": "75429f5d-3c39-4a6a-b600-7a46dbb71893"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "true_y = list(dev_set['target'])\n",
        "print('F1 = ', f1_score(y_true = true_y, y_pred = pred, pos_label=\"1\"))\n",
        "print('Accuracy = ', precision_score(y_true = true_y, y_pred = pred, pos_label=\"1\"))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 =  0.6321243523316062\n",
            "Accuracy =  0.6110183639398998\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8KrUbbEbjQd"
      },
      "source": [
        "Try SVC modeling (support vector classifier). Fit data we provide, returning best fit\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MXnqjUgRhFU0"
      },
      "source": [
        "train['tokenized_stem'] = tokenizer(train[\"stemmed_text\"])\n",
        "\n",
        "val_set = train.iloc[:1500]\n",
        "train_set = train.iloc[1500:]\n",
        "\n",
        "val_x = list(val_set[\"tokenized_stem\"])\n",
        "val_y = list(val_set[\"target\"])\n",
        "\n",
        "train_x = list(train_set[\"tokenized_stem\"])\n",
        "train_y = list(train_set[\"target\"])"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHLgLuBb5tsa"
      },
      "source": [
        "\n",
        "tagged_docs = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_x)]\n",
        "model = Doc2Vec(tagged_docs, vector_size=200, dm = 0, window=7, min_count=1, epochs = 40)\n",
        "\n",
        "train_vec = []\n",
        "val_vec = []\n",
        "for text in train_x:\n",
        "  train_vec.append(model.infer_vector(text, steps = 20))\n",
        "\n",
        "for text in val_x:\n",
        "  val_vec.append(model.infer_vector(text, steps = 20))\n",
        "\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k34wlTO4dJTi",
        "outputId": "2b46fcb7-cc4d-4f20-f454-0b0f05219cc6"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svc = SVC(random_state=1, C = 5, gamma = 6, kernel = 'rbf', probability = True)\n",
        "svc.fit(train_vec, train_y)\n",
        "\n",
        "svc_pred = svc.predict(val_vec)\n",
        "\n",
        "print('F1 = ', f1_score(y_true = val_y, y_pred = svc_pred, pos_label=\"1\"))\n",
        "print('Accuracy = ', precision_score(y_true = val_y, y_pred = svc_pred, pos_label=\"1\"))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 =  0.059027777777777776\n",
            "Accuracy =  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCkXnb3Hfiij",
        "outputId": "117e20f0-6251-4b34-a248-79510cc81273"
      },
      "source": [
        "# better with precision, less accurate with recall (vector-200)\n",
        "evaluate_pred(true_y, svc_pred)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'F1': 0.5782312925170068,\n",
              " 'accuracy': 0.752,\n",
              " 'precision': 0.7894736842105263,\n",
              " 'recall': 0.4561717352415027}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg-ReLxbf1Xo",
        "outputId": "822c70ee-a342-4b11-a6b0-74386168b5a4"
      },
      "source": [
        "# better with precision, less accurate with recall (vector - 1000)\n",
        "# more accurate precision, but hurts recall \n",
        "# works better with smaller vectors \n",
        "evaluate_pred(true_y, svc_pred)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'F1': 0.059027777777777776,\n",
              " 'accuracy': 0.6386666666666667,\n",
              " 'precision': 1.0,\n",
              " 'recall': 0.03041144901610018}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lpk6qwty62Tl"
      },
      "source": [
        "# predict on test set (prep)\n",
        "# unstemmed_list = test['text'].tolist()\n",
        "# test['stemmed_text'] = stem(unstemmed_list)\n",
        "# test['stemmed_text'] = test['stemmed_text'].str.replace('\\d+', '')\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "he7_gMXI9jyl"
      },
      "source": [
        "Viz Ideas:\n",
        "1. Class Distribution - Sindhu\n",
        "2. Word cloud of keywords for both classes - Hearan\n",
        "3. Bi-gram bar plot (bar plot of most frequently occuring words for both classes) - Pranshu\n",
        "4. Average length of tweet for both classes - Sindhu\n",
        "5. \n",
        "\n",
        "Data processing proposed steps: (Done)\n",
        "1. Removal of punctuations, unwanted text\n",
        "2. Performing stemming/lemmatization\n",
        "3. Spell check\n",
        "4. Removing emojis\n",
        "5. Replacing common acronyms/shorhands\n",
        "6.\n",
        "\n",
        "\n",
        "EDA Ideas:\n",
        "1. Clustering Tweets from same location over a short time period - (if many tweets come from the same location in a short time containing keywords for disasters they might actually be a disaster)\n",
        "2. Clustering tweets via keyword - if the same keyword is being used over a short period of time it might mean a disaster\n",
        "3. \n",
        "\n",
        "Models:\n",
        "1. Word2Vec with GloVe\n",
        "2. Simple LSTMs\n",
        "3. LSTMs with Hidden layers\n",
        "4. (Possibly) BERT\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBp1qk5qAIT-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y22W1VLAcxh"
      },
      "source": [
        "(Rough sketch)\n",
        "\n",
        "Project doc: (numbers denote page numbers)\n",
        "\n",
        "1. Names, Project title)\n",
        "2. Introduction:\n",
        "What is the problem we're trying to solve, How are we using NLP to solve the problem, Proposed method (in brief) on how we'll solve, Impact of problem on society (use-case irl)\n",
        "3. Dataset used, data cleaning methods (and why it was necessary)\n",
        "4. EDA: \n",
        "5. Visualizations\n",
        "6. Models used (1 page each per model):\n",
        "Explaining the model architecture in brief, why was it best to use this model (or appropriate), what was the model parameters (explain a few if needed), what were the results, and what metrics were used to obtain the resutls\n",
        "9. Conclusions, model comparisons, final words\n",
        "10. Team member contributions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0n9iOROBAsob"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}